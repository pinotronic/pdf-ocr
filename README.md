# Optimizador de PDF con DeepSeek OCR

AplicaciÃ³n de escritorio para extraer y optimizar texto de archivos PDF usando OCR con inteligencia artificial.

## ğŸš€ CaracterÃ­sticas

- **Dos modos de operaciÃ³n**:
  - ğŸ  **Modo Local**: Usa Ollama con modelos DeepSeek instalados localmente (sin costos, privacidad total)
  - â˜ï¸ **Modo API**: Usa la API de DeepSeek en la nube (requiere API key)
- ExtracciÃ³n de texto inteligente (texto nativo o OCR)
- Interfaz grÃ¡fica intuitiva
- Barra de progreso en tiempo real
- OptimizaciÃ³n automÃ¡tica del PDF resultante

## ğŸ“‹ Requisitos Previos

### Para Modo Local (Recomendado)
1. **Ollama** instalado en tu sistema
   - Windows: Descarga desde https://ollama.ai/download
   - Verifica la instalaciÃ³n: `ollama --version`

2. **Modelo DeepSeek** descargado
   ```bash
   ollama pull deepseek-r1:1.5b
   ```
   
   Modelos disponibles:
   - `deepseek-r1:1.5b` - RÃ¡pido, requiere ~1GB RAM (Recomendado para inicio)
   - `deepseek-r1:7b` - Balanceado, requiere ~4GB RAM
   - `deepseek-r1:14b` - Mejor precisiÃ³n, requiere ~8GB RAM

### Para Modo API
- API Key de DeepSeek (obtener en https://platform.deepseek.com)

## ğŸ”§ InstalaciÃ³n

1. **Clonar o descargar el repositorio**

2. **Instalar dependencias de Python**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar el archivo .env**
   
   Copia el archivo de ejemplo:
   ```bash
   copy .env.example .env
   ```
   
   Edita `.env` segÃºn tu modo preferido:
   
   **Para modo LOCAL (Ollama):**
   ```env
   USE_LOCAL_MODEL=true
   OLLAMA_URL=http://localhost:11434
   OLLAMA_MODEL=deepseek-r1:1.5b
   ```
   
   **Para modo API:**
   ```env
   USE_LOCAL_MODEL=false
   DEEPSEEK_API_KEY=tu_api_key_aqui
   ```

4. **Verificar instalaciÃ³n**
   ```bash
   python test_ollama.py
   ```

## ğŸ¯ Uso

### Iniciar la aplicaciÃ³n
```bash
python main.py
```

### Pasos para optimizar un PDF:
1. Haz clic en **"Examinar"** y selecciona tu archivo PDF
2. Haz clic en **"Optimizar PDF"**
3. Espera a que el procesamiento termine
4. El archivo optimizado se guardarÃ¡ con el sufijo `_optimizado.pdf`

## ğŸ§ª Pruebas

### Probar conexiÃ³n con Ollama
```bash
python test_ollama.py
```

### Probar extracciÃ³n de texto (si existe test_api.py)
```bash
python test_api.py
```

## ğŸ“ Estructura del Proyecto

```
pdfDeepsek/
â”œâ”€â”€ main.py                 # Punto de entrada
â”œâ”€â”€ config.py              # ConfiguraciÃ³n
â”œâ”€â”€ deepseek_client.py     # Cliente DeepSeek (API y Local)
â”œâ”€â”€ pdf_processor.py       # Procesamiento de PDFs
â”œâ”€â”€ ui_interface.py        # Interfaz grÃ¡fica
â”œâ”€â”€ test_ollama.py         # Prueba de Ollama
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ .env                   # ConfiguraciÃ³n local (no subir a git)
â””â”€â”€ .env.example          # Plantilla de configuraciÃ³n
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar modelo de Ollama

En `.env`, modifica:
```env
OLLAMA_MODEL=deepseek-r1:7b
```

Luego descarga el modelo:
```bash
ollama pull deepseek-r1:7b
```

### Cambiar URL de Ollama (si usas servidor remoto)

```env
OLLAMA_URL=http://tu-servidor:11434
```

### Alternar entre modo Local y API

Simplemente cambia en `.env`:
```env
USE_LOCAL_MODEL=true   # o false
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "No se puede conectar a Ollama"
- Verifica que Ollama estÃ© corriendo: `ollama serve`
- Verifica el puerto: por defecto es 11434
- En Windows, Ollama se inicia automÃ¡ticamente como servicio

### Error: "Modelo no encontrado"
- Lista modelos instalados: `ollama list`
- Instala el modelo: `ollama pull deepseek-r1:1.5b`
- Verifica el nombre en `.env` coincida con el instalado

### Error: "API Key no configurada"
- Si usas modo API, verifica que `DEEPSEEK_API_KEY` estÃ© en `.env`
- Si usas modo local, asegÃºrate que `USE_LOCAL_MODEL=true`

### PDF no se procesa correctamente
- Verifica que poppler estÃ© instalado (carpeta `poppler/` en el proyecto)
- Verifica que el PDF no estÃ© protegido o encriptado
- Revisa los logs en la interfaz

## ğŸ” Privacidad y Seguridad

- **Modo Local**: Todo el procesamiento ocurre en tu mÃ¡quina, ningÃºn dato sale de tu computadora
- **Modo API**: Los datos se envÃ­an a los servidores de DeepSeek para procesamiento

## ğŸ“ Notas

- El primer uso del modelo puede tardar mientras se carga en memoria
- PDFs grandes pueden requerir varios minutos de procesamiento
- Se recomienda modo local para documentos sensibles

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor abre un issue primero para discutir cambios mayores.

## ğŸ“„ Licencia

[Especifica tu licencia aquÃ­]

## ğŸ‘¨â€ğŸ’» Autor

[Tu nombre/contacto]
